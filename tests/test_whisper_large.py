#!/usr/bin/env python3
"""
Whisper Large-v3 ëª¨ë¸ í…ŒìŠ¤íŠ¸
ê³ ì„±ëŠ¥ Whisper large-v3 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
  python tests/test_whisper_large.py
"""

import whisper
import pyaudio
import numpy as np
import torch
import time
import queue
import threading

# CPU ê°•ì œ ì‚¬ìš©
device = "cpu"
print(f"Using device: {device}")
model = whisper.load_model("large-v3", device=device)
print("Model loaded with large-v3")

CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000

p = pyaudio.PyAudio()
stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
q = queue.Queue()

def record_audio():
    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        q.put(data)

threading.Thread(target=record_audio, daemon=True).start()

print("í•œêµ­ì–´ë¡œ ë§í•´ì£¼ì„¸ìš”... (Ctrl+Cë¡œ ì¢…ë£Œ)")

try:
    while True:
        start_time = time.time()
        audio_buffer = []
        for _ in range(10):  # 0.25ì´ˆ ë¶„ëŸ‰
            audio_buffer.append(q.get())
        audio_data = b''.join(audio_buffer)
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
        result = model.transcribe(audio_np, language="ko")
        text = result["text"].strip()
        if text:
            print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text} (ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.2f}s)")

if __name__ == "__main__":
    print("ğŸ¤ Whisper Large-v3 í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ê³ ì„±ëŠ¥ ëª¨ë¸ë¡œ ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    print("Ctrl+Cë¡œ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("=" * 50)
    
    try:
        main()
    except KeyboardInterrupt:
        print("\n\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        try:
            stream.stop_stream()
            stream.close()
            audio.terminate()
        except:
            pass

stream.stop_stream()
stream.close()
p.terminate()