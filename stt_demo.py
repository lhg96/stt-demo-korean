#!/usr/bin/env python3
"""
STT Demo - í†µí•©ëœ ìŒì„± ì¸ì‹ ë°ëª¨ ì• í”Œë¦¬ì¼€ì´ì…˜
Whisperì™€ Vosk ëª¨ë¸ì„ ì§€ì›í•˜ëŠ” GUI ì• í”Œë¦¬ì¼€ì´ì…˜

Usage:
  python stt_demo.py           # GUI ì‹¤í–‰ (ê¸°ë³¸ê°’)
  python stt_demo.py gui       # GUI ì‹¤í–‰
  python stt_demo.py check     # íŒ¨í‚¤ì§€ í™•ì¸
  python stt_demo.py install   # íŒ¨í‚¤ì§€ ì„¤ì¹˜
  python stt_demo.py help      # ë„ì›€ë§
"""

import sys
import os
import json
import time
import threading
import queue
import subprocess
from typing import Optional
from pathlib import Path

import numpy as np
import pyaudio
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QVBoxLayout, QHBoxLayout, QWidget, 
    QLabel, QPushButton, QComboBox, QTextEdit, QProgressBar, 
    QGroupBox, QCheckBox, QSlider, QTabWidget, QStatusBar,
    QMessageBox, QFileDialog
)
from PyQt5.QtCore import QThread, pyqtSignal, QTimer, Qt
from PyQt5.QtGui import QFont, QIcon
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
import matplotlib.style as mplstyle

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

try:
    from vosk import Model, KaldiRecognizer
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False




def check_requirements():
    """í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸"""
    required_packages = {
        'PyQt5': ('PyQt5.QtCore', 'pip install PyQt5'),
        'numpy': ('numpy', 'pip install numpy'),
        'pyaudio': ('pyaudio', 'pip install pyaudio'),
        'matplotlib': ('matplotlib', 'pip install matplotlib')
    }
    
    missing_packages = []
    
    for package_name, (import_name, install_cmd) in required_packages.items():
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append((package_name, install_cmd))
    
    if missing_packages:
        print("âŒ Missing required packages:")
        for package, cmd in missing_packages:
            print(f"   - {package}: {cmd}")
        return False
    
    return True


def check_optional_packages():
    """ì„ íƒì  íŒ¨í‚¤ì§€ í™•ì¸"""
    available = {}
    
    if WHISPER_AVAILABLE:
        available['whisper'] = True
        print("âœ… Whisper available")
    else:
        print("âš ï¸  Whisper not installed: pip install openai-whisper")
    
    if VOSK_AVAILABLE:
        available['vosk'] = True
        print("âœ… Vosk available")
    else:
        print("âš ï¸  Vosk not installed: pip install vosk")
    
    return available


def install_packages():
    """íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜"""
    packages = [
        "PyQt5", "numpy", "pyaudio", "matplotlib",
        "openai-whisper", "vosk"
    ]
    
    python_path = get_venv_python()
    
    for package in packages:
        print(f"ğŸ“¦ Installing {package}...")
        try:
            subprocess.run([python_path, "-m", "pip", "install", package], 
                         check=True, capture_output=True)
            print(f"âœ… {package} installed successfully")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Failed to install {package}: {e}")


def get_venv_python():
    """ê°€ìƒí™˜ê²½ Python ê²½ë¡œ ë°˜í™˜"""
    venv_python = os.path.join(os.path.dirname(__file__), "venv", "bin", "python")
    if os.path.exists(venv_python):
        return venv_python
    return sys.executable


def show_help():
    """ë„ì›€ë§ í‘œì‹œ"""
    help_text = """
STT Demo - Speech-to-Text Demo Application

Commands:
  gui      Start GUI application (default)
  check    Check installed packages
  install  Install required packages
  help     Show this help

Examples:
  python stt_demo.py           # Run GUI
  python stt_demo.py gui       # Run GUI
  python stt_demo.py check     # Check packages
  python stt_demo.py install   # Install packages

Features:
  - Real-time speech recognition
  - Support for Whisper and Vosk models
  - Audio visualization (waveform, spectrum)
  - Korean and English support
  - Export results to text files
"""
    print(help_text)


class AudioRecorderThread(QThread):
    """ì˜¤ë””ì˜¤ ë…¹ìŒ ì „ìš© ìŠ¤ë ˆë“œ - ì½œë°± ë°©ì‹ ì‚¬ìš©"""
    audio_data = pyqtSignal(np.ndarray)
    error_occurred = pyqtSignal(str)
    recording_finished = pyqtSignal(np.ndarray)  # ì „ì²´ ë…¹ìŒ ë°ì´í„° ì‹œê·¸ë„
    
    def __init__(self):
        super().__init__()
        self.is_recording = False
        self.terminate_flag = False  # ì•ˆì „í•œ ì¢…ë£Œ í”Œë˜ê·¸
        self.recorded_data = []  # ì „ì²´ ë…¹ìŒ ë°ì´í„° ì €ì¥
        self.audio_queue = queue.Queue()
        
        # PyAudio ì„¤ì •
        self.CHUNK = 1024
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        
        self.p = None
        self.stream = None
    
    def audio_callback(self, in_data, frame_count, time_info, status):
        """PyAudio ìŠ¤íŠ¸ë¦¬ë° ì½œë°±"""
        if self.is_recording:
            self.audio_queue.put(in_data)
        return (None, pyaudio.paContinue)
        
    def start_recording(self):
        """ë…¹ìŒ ì‹œì‘"""
        try:
            self.recorded_data = []  # ë…¹ìŒ ë°ì´í„° ì´ˆê¸°í™”
            self.terminate_flag = False
            self.is_recording = True
            
            self.p = pyaudio.PyAudio()
            
            # ì½œë°± ë°©ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ ìƒì„±
            self.stream = self.p.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                frames_per_buffer=self.CHUNK,
                stream_callback=self.audio_callback
            )
            
            self.stream.start_stream()
            self.start()  # ìŠ¤ë ˆë“œ ì‹œì‘
            
        except Exception as e:
            self.error_occurred.emit(f"Recording start error: {str(e)}")
    
    def stop_recording(self):
        """ë…¹ìŒ ì¤‘ì§€ - test_pyqt5_gui.pyì˜ ì•ˆì „í•œ ì¢…ë£Œ ë°©ì‹"""
        self.terminate_flag = True
        self.is_recording = False
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        if self.p:
            self.p.terminate()
        
        # ì „ì²´ ë…¹ìŒ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ê²°í•©
        if self.recorded_data:
            combined_audio = np.concatenate(self.recorded_data)
            self.recording_finished.emit(combined_audio)
            print(f"ğŸ¤ Recording finished. Total length: {len(combined_audio)} samples")
        
        self.quit()
        self.wait()
    
    def run(self):
        """ë…¹ìŒ ë£¨í”„ - ì½œë°±ì—ì„œ ë°›ì€ ë°ì´í„° ì²˜ë¦¬"""
        try:
            while not self.terminate_flag:
                try:
                    # ì½œë°±ì—ì„œ ë°ì´í„° ë°›ê¸° (1ì´ˆ íƒ€ì„ì•„ì›ƒ)
                    data = self.audio_queue.get(timeout=1)
                    audio_np = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                    
                    # ì „ì²´ ë…¹ìŒ ë°ì´í„°ì— ì¶”ê°€
                    self.recorded_data.append(audio_np)
                    
                    # ì‹¤ì‹œê°„ ì‹œê°í™”ë§Œ ì „ì†¡
                    self.audio_data.emit(audio_np)
                    
                except queue.Empty:
                    continue  # íƒ€ì„ì•„ì›ƒ ì‹œ ê³„ì†
                    
        except Exception as e:
            self.error_occurred.emit(f"Recording error: {str(e)}")


class STTThread(QThread):
    """ì¼íšŒì„± STT ì²˜ë¦¬ ì „ìš© ìŠ¤ë ˆë“œ"""
    result_ready = pyqtSignal(str, float)
    
    def __init__(self, model_type="whisper", audio_data=None):
        super().__init__()
        self.model_type = model_type
        self.audio_data = audio_data
        self.model = None
        self.recognizer = None
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.init_model()
    
    def init_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            if self.model_type == "whisper" and WHISPER_AVAILABLE:
                print("ğŸ”„ Loading Whisper model...")
                self.model = whisper.load_model("base")
                print("âœ… Whisper model loaded")
            elif self.model_type == "vosk" and VOSK_AVAILABLE:
                model_path = "./vosk-model-small-ko-0.22"
                print(f"ğŸ”„ Loading Vosk model from {model_path}...")
                if os.path.exists(model_path):
                    vosk_model = Model(model_path)
                    self.recognizer = KaldiRecognizer(vosk_model, 16000)
                    # JSON ì¶œë ¥ í™œì„±í™”
                    self.recognizer.SetWords(True)
                    print("âœ… Vosk Korean model loaded")
                else:
                    print(f"âŒ Vosk model not found: {model_path}")
                    print("   Download: wget https://alphacephei.com/vosk/models/vosk-model-small-ko-0.22.zip")
            else:
                print(f"âŒ Model {self.model_type} not available")
        except Exception as e:
            print(f"Model initialization error: {e}")
            self.model = None
            self.recognizer = None

    
    def run(self):
        """ì˜¤ë””ì˜¤ STT ì²˜ë¦¬"""
        try:
            if self.audio_data is not None and len(self.audio_data) > 0:
                print(f"ğŸ” Processing audio for STT (length: {len(self.audio_data)} samples)...")
                
                # ë„ˆë¬´ ì¡°ìš©í•œ ê²½ìš° ê±´ë„ˆë›°ê¸°
                if np.max(np.abs(self.audio_data)) < 0.01:
                    print("ğŸ”‡ Audio too quiet, skipping...")
                    return
                
                # STT ì²˜ë¦¬
                text = self.process_audio(self.audio_data)
                
                if text and text.strip() and len(text.strip()) > 1:
                    confidence = 0.85
                    self.result_ready.emit(text.strip(), confidence)
                    print(f"âœ… STT Result: {text.strip()}")
                else:
                    print("âŒ No speech detected or text too short")
                    
        except Exception as e:
            print(f"STT processing error: {e}")
    
    def process_audio(self, audio_data):
        """ì˜¤ë””ì˜¤ STT ì²˜ë¦¬ - test_pyqt5_gui.pyì™€ ë™ì¼í•œ ë°©ì‹"""
        try:
            # ìµœì†Œ 3ì´ˆ ì´ìƒì˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            min_samples = 16000 * 3  # 3ì´ˆ
            if len(audio_data) < min_samples:
                print(f"ğŸ”‡ Audio too short ({len(audio_data)} samples), minimum {min_samples} required")
                return ""
            
            if self.model_type == "whisper" and self.model:
                print(f"ğŸ¤ Processing audio with Whisper ({len(audio_data)} samples)...")
                # Whisper í•œêµ­ì–´ ì²˜ë¦¬ - numpy ë°°ì—´ ì§ì ‘ ì „ë‹¬
                result = self.model.transcribe(audio_data, language="ko")
                text = result["text"].strip()
                if text:
                    print(f"ğŸ¤ Whisper result: {text}")
                    return text
                else:
                    print("ğŸ¤ Whisper: No speech detected")
                    return ""
                
            elif self.model_type == "vosk" and self.recognizer:
                print(f"ğŸ¤ Processing audio with Vosk ({len(audio_data)} samples)...")
                # Vosk í•œêµ­ì–´ ì²˜ë¦¬
                audio_int16 = (audio_data * 32768).astype(np.int16)
                audio_bytes = audio_int16.tobytes()
                
                # ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
                if self.recognizer.AcceptWaveform(audio_bytes):
                    result = json.loads(self.recognizer.Result())
                    text = result.get("text", "").strip()
                    if text:
                        print(f"ğŸ¤ Vosk result: {text}")
                        return text
                    else:
                        print("ğŸ¤ Vosk: No speech detected")
                        return ""
                else:
                    print("ğŸ¤ Vosk: Processing incomplete")
                    return ""
                    
            else:
                print(f"âŒ No valid STT model available: {self.model_type}")
                return ""
                
        except Exception as e:
            print(f"Audio processing error: {e}")
            return ""


class AudioVisualizerWidget(QWidget):
    """ì˜¤ë””ì˜¤ ì‹œê°í™” ìœ„ì ¯"""
    
    def __init__(self):
        super().__init__()
        self.setup_ui()
        
        # ë°ì´í„° ë²„í¼
        self.waveform_data = np.zeros(1024)
        self.spectrum_data = np.zeros(512)
        
        # ì—…ë°ì´íŠ¸ íƒ€ì´ë¨¸
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_plots)
        self.timer.start(50)  # 50ms ê°„ê²©
    
    def setup_ui(self):
        """UI ì„¤ì •"""
        layout = QVBoxLayout()
        
        # Matplotlib Figure
        self.figure, (self.waveform_ax, self.spectrum_ax) = plt.subplots(2, 1, figsize=(10, 8))
        self.canvas = FigureCanvas(self.figure)
        layout.addWidget(self.canvas)
        
        # ì´ˆê¸° í”Œë¡¯ ì„¤ì •
        self.waveform_line, = self.waveform_ax.plot([], [], 'g-')
        self.waveform_ax.set_title('Waveform')
        self.waveform_ax.set_ylim(-1, 1)
        self.waveform_ax.set_xlim(0, 1024)
        self.waveform_ax.grid(True)
        
        self.spectrum_line, = self.spectrum_ax.plot([], [], 'b-')
        self.spectrum_ax.set_title('Frequency Spectrum')
        self.spectrum_ax.set_xlim(0, 8000)
        self.spectrum_ax.set_ylim(-80, 0)
        self.spectrum_ax.grid(True)
        
        plt.tight_layout(pad=2.0)
        self.setLayout(layout)
    
    def update_audio_data(self, audio_data):
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        self.waveform_data = audio_data[:1024] if len(audio_data) >= 1024 else np.zeros(1024)
        
        # FFT ê³„ì‚°
        if len(audio_data) > 0:
            fft_data = np.abs(np.fft.fft(audio_data[:1024]))
            self.spectrum_data = 20 * np.log10(fft_data[:512] + 1e-6)
    
    def update_plots(self):
        """í”Œë¡¯ ì—…ë°ì´íŠ¸"""
        # íŒŒí˜• ì—…ë°ì´íŠ¸
        self.waveform_line.set_data(range(len(self.waveform_data)), self.waveform_data)
        
        # ìŠ¤í™íŠ¸ëŸ¼ ì—…ë°ì´íŠ¸
        freqs = np.linspace(0, 8000, len(self.spectrum_data))
        self.spectrum_line.set_data(freqs, self.spectrum_data)
        
        self.canvas.draw_idle()


class STTDemoMainWindow(QMainWindow):
    """ë©”ì¸ GUI ìœˆë„ìš°"""
    
    def __init__(self):
        super().__init__()
        self.recorder_thread = None
        self.stt_thread = None
        self.is_recording = False
        self.selected_model = "whisper"
        self.setup_ui()
        self.setup_connections()
        
    def setup_ui(self):
        """UI ì„¤ì •"""
        self.setWindowTitle("STT Demo - Speech Recognition")
        self.setGeometry(100, 100, 1200, 800)
        
        # ì „ì²´ ì•± í°íŠ¸ í¬ê¸° ì„¤ì •
        font = QFont()
        font.setPointSize(9)  # í°íŠ¸ í¬ê¸°ë¥¼ 9ë¡œ ì„¤ì •
        self.setFont(font)
        QApplication.instance().setFont(font)
        
        # ì¤‘ì•™ ìœ„ì ¯
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒ
        main_layout = QHBoxLayout()
        
        # ì™¼ìª½ íŒ¨ë„ (ì»¨íŠ¸ë¡¤)
        left_panel = self.create_control_panel()
        main_layout.addWidget(left_panel, 1)
        
        # ì˜¤ë¥¸ìª½ íŒ¨ë„ (ì‹œê°í™”)
        right_panel = self.create_visualization_panel()
        main_layout.addWidget(right_panel, 2)
        
        central_widget.setLayout(main_layout)
        
        # ìƒíƒœë°”
        self.statusBar().showMessage("Ready")
    
    def create_control_panel(self):
        """ì»¨íŠ¸ë¡¤ íŒ¨ë„ ìƒì„±"""
        panel = QWidget()
        layout = QVBoxLayout()
        
        # ëª¨ë¸ ì„ íƒ
        model_group = QGroupBox("Model Settings")
        model_layout = QVBoxLayout()
        
        self.model_combo = QComboBox()
        available_models = []
        if WHISPER_AVAILABLE:
            self.model_combo.addItem("Whisper")
            available_models.append("Whisper")
        if VOSK_AVAILABLE:
            self.model_combo.addItem("Vosk")
            available_models.append("Vosk")
        
        # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
        if not available_models:
            self.model_combo.addItem("No STT Model Available")
            
        model_layout.addWidget(QLabel("Model:"))
        model_layout.addWidget(self.model_combo)
        
        # ìƒíƒœ ë¼ë²¨ ì¶”ê°€
        self.model_status_label = QLabel()
        self.update_model_status()
        model_layout.addWidget(self.model_status_label)
        
        model_group.setLayout(model_layout)
        layout.addWidget(model_group)
        
        # ë…¹ìŒ ì»¨íŠ¸ë¡¤
        record_group = QGroupBox("Recording Control")
        record_layout = QVBoxLayout()
        
        self.record_btn = QPushButton("Start Recording")
        self.record_btn.setStyleSheet("QPushButton { background-color: #4CAF50; }")
        record_layout.addWidget(self.record_btn)
        
        self.stop_btn = QPushButton("Stop Recording")
        self.stop_btn.setEnabled(False)
        self.stop_btn.setStyleSheet("QPushButton { background-color: #f44336; }")
        record_layout.addWidget(self.stop_btn)
        
        record_group.setLayout(record_layout)
        layout.addWidget(record_group)
        
        # ê²°ê³¼ í‘œì‹œ
        result_group = QGroupBox("Recognition Results")
        result_layout = QVBoxLayout()
        
        self.result_text = QTextEdit()
        self.result_text.setStyleSheet("QTextEdit { font-size: 10px; }")
        self.result_text.setPlaceholderText("Recognition results will appear here...")
        result_layout.addWidget(self.result_text)
        
        # ë²„íŠ¼ë“¤
        button_layout = QHBoxLayout()
        
        self.clear_btn = QPushButton("Clear")
        self.save_btn = QPushButton("Save")
        button_layout.addWidget(self.clear_btn)
        button_layout.addWidget(self.save_btn)
        
        result_layout.addLayout(button_layout)
        result_group.setLayout(result_layout)
        layout.addWidget(result_group)
        
        layout.addStretch()
        panel.setLayout(layout)
        return panel
    
    def create_visualization_panel(self):
        """ì‹œê°í™” íŒ¨ë„ ìƒì„±"""
        self.visualizer = AudioVisualizerWidget()
        return self.visualizer
    
    def setup_connections(self):
        """ì‹œê·¸ë„-ìŠ¬ë¡¯ ì—°ê²°"""
        self.record_btn.clicked.connect(self.start_recording)
        self.stop_btn.clicked.connect(self.stop_recording)
        self.clear_btn.clicked.connect(self.clear_results)
        self.save_btn.clicked.connect(self.save_results)
        self.model_combo.currentTextChanged.connect(self.change_model)
    
    def update_model_status(self):
        """ëª¨ë¸ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        status_text = "Available models: "
        if WHISPER_AVAILABLE:
            status_text += "Whisper âœ… "
        else:
            status_text += "Whisper âŒ "
        if VOSK_AVAILABLE:
            status_text += "Vosk âœ…"
        else:
            status_text += "Vosk âŒ"
        self.model_status_label.setText(status_text)
        self.model_status_label.setStyleSheet("color: #888888; font-size: 8px;")
    
    def start_recording(self):
        """ë…¹ìŒ ì‹œì‘"""
        if self.is_recording:
            return
        
        # ëª¨ë¸ ì„ íƒ í™•ì¸
        selected_model = self.model_combo.currentText().lower()
        if selected_model == "no stt model available":
            QMessageBox.warning(self, "Warning", "No STT model available. Please install Whisper or Vosk.")
            return
            
        try:
            # ì˜¤ë””ì˜¤ ë ˆì½”ë” ì‹œì‘
            self.recorder_thread = AudioRecorderThread()
            self.recorder_thread.audio_data.connect(self.on_audio_data)
            self.recorder_thread.recording_finished.connect(self.on_recording_finished)
            self.recorder_thread.error_occurred.connect(self.on_error)
            self.recorder_thread.start_recording()
            
            self.is_recording = True
            self.selected_model = selected_model
            self.record_btn.setEnabled(False)
            self.stop_btn.setEnabled(True)
            self.statusBar().showMessage(f"Recording with {selected_model.title()} model...")
            
            # ê²°ê³¼ ì˜ì—­ì— ì‹œì‘ ë©”ì‹œì§€ ì¶”ê°€
            timestamp = time.strftime("%H:%M:%S")
            start_msg = f"[{timestamp}] === Recording started with {selected_model.title()} model ===\n"
            self.result_text.append(start_msg)
            
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to start recording: {str(e)}")
    
    def stop_recording(self):
        """ë…¹ìŒ ì¤‘ì§€"""
        if not self.is_recording:
            return
        
        self.is_recording = False
        
        if self.recorder_thread:
            self.statusBar().showMessage("Stopping recording and processing...")
            self.recorder_thread.stop_recording()
            self.recorder_thread = None
        
        self.record_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
    
    def on_audio_data(self, audio_data):
        """ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  (ì‹¤ì‹œê°„ ì‹œê°í™”ìš©)"""
        # ì‹¤ì‹œê°„ ì‹œê°í™” ì—…ë°ì´íŠ¸
        self.visualizer.update_audio_data(audio_data)
        
        # ì˜¤ë””ì˜¤ ë ˆë²¨ ì²´í¬ (ë””ë²„ê¹…ìš©)
        audio_level = np.max(np.abs(audio_data))
        if audio_level > 0.1:  # ì¶©ë¶„í•œ ìŒì„±ì´ ê°ì§€ë˜ë©´
            self.statusBar().showMessage(f"ğŸ¤ Audio level: {audio_level:.3f} - Speaking detected")
    
    def on_stt_result(self, text, confidence):
        """STT ê²°ê³¼ ìˆ˜ì‹  ë° í‘œì‹œ"""
        if text and text.strip():
            timestamp = time.strftime("%H:%M:%S")
            current_model = self.selected_model.title() if hasattr(self, 'selected_model') else "Unknown"
            result_line = f"[{timestamp}] [{current_model}] {text.strip()} (confidence: {confidence:.2f})\n"
            self.result_text.append(result_line)
            self.statusBar().showMessage(f"Recognized ({current_model}): {text.strip()[:50]}...")
            
            # ì»¤ì„œë¥¼ ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ë™
            cursor = self.result_text.textCursor()
            cursor.movePosition(cursor.End)
            self.result_text.setTextCursor(cursor)
    
    def on_recording_finished(self, audio_data):
        """ë…¹ìŒ ì™„ë£Œ ì‹œ STT ì²˜ë¦¬ ì‹œì‘"""
        print(f"ğŸ¤ Recording finished, starting STT processing...")
        
        # STT ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ìƒì„± ë° ì‹œì‘
        selected_model = getattr(self, 'selected_model', 'whisper')
        self.stt_thread = STTThread(selected_model, audio_data)
        self.stt_thread.result_ready.connect(self.on_stt_result)
        self.stt_thread.finished.connect(self.on_stt_finished)
        self.stt_thread.start()
    
    def on_stt_finished(self):
        """ì‹¤ì‹œê°„ STT ì²˜ë¦¬ ì™„ë£Œ"""
        self.statusBar().showMessage("Ready")
        if self.stt_thread:
            self.stt_thread = None
    
    def on_error(self, error_msg):
        """ì˜¤ë¥˜ ì²˜ë¦¬"""
        QMessageBox.warning(self, "Warning", error_msg)
        self.stop_recording()
    
    def clear_results(self):
        """ê²°ê³¼ ì§€ìš°ê¸°"""
        self.result_text.clear()
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save Results", "stt_results.txt", "Text Files (*.txt)")
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(self.result_text.toPlainText())
                QMessageBox.information(self, "Success", f"Results saved to {file_path}")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to save: {str(e)}")
    
    def change_model(self, model_name):
        """ëª¨ë¸ ë³€ê²½"""
        if self.is_recording:
            reply = QMessageBox.question(self, "Model Change", 
                                       "Recording is in progress. Stop recording to change model?",
                                       QMessageBox.Yes | QMessageBox.No)
            if reply == QMessageBox.Yes:
                self.stop_recording()
            else:
                return
                
        # ëª¨ë¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.statusBar().showMessage(f"Selected model: {model_name}")
        
        # Vosk ëª¨ë¸ ì‚¬ìš© ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
        if model_name.lower() == "vosk":
            model_path = "./vosk-model-small-ko-0.22"
            if not os.path.exists(model_path):
                QMessageBox.information(self, "Vosk Model Info", 
                                       f"Vosk Korean model not found at: {model_path}\n\n"
                                       "To download:\n"
                                       "wget https://alphacephei.com/vosk/models/vosk-model-small-ko-0.22.zip\n"
                                       "unzip vosk-model-small-ko-0.22.zip")
    
    def closeEvent(self, event):
        """ì°½ ë‹«ê¸° ì´ë²¤íŠ¸ - test_pyqt5_gui.pyì˜ ì•ˆì „í•œ ì¢…ë£Œ ë°©ì‹"""
        if self.is_recording:
            self.stop_recording()
        
        # ìŠ¤ë ˆë“œë“¤ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ
        if self.recorder_thread and self.recorder_thread.isRunning():
            self.recorder_thread.stop_recording()
        if self.stt_thread and self.stt_thread.isRunning():
            self.stt_thread.quit()
            self.stt_thread.wait()
            
        event.accept()


def run_gui():
    """GUI ì‹¤í–‰"""
    app = QApplication(sys.argv)
    app.setApplicationName("STT Demo")
    
    # ë‹¤í¬ í…Œë§ˆ ì„¤ì •
    app.setStyleSheet("""
        QMainWindow { background-color: #2b2b2b; color: #ffffff; }
        QWidget { background-color: #2b2b2b; color: #ffffff; }
        QGroupBox { 
            font-weight: bold; 
            border: 1px solid #555; 
            margin: 5px; 
            padding: 5px;
            border-radius: 4px;
        }
        QGroupBox::title { 
            subcontrol-origin: margin; 
            left: 10px; 
            padding: 0 5px 0 5px; 
        }
        QPushButton { 
            padding: 8px; 
            border-radius: 4px; 
            border: 1px solid #555;
            font-weight: bold;
        }
        QPushButton:hover {
            border: 1px solid #777;
            background-color: #3c3c3c;
        }
        QComboBox { 
            padding: 5px; 
            border: 1px solid #555; 
            border-radius: 4px;
            background-color: #3c3c3c;
        }
        QTextEdit { 
            border: 1px solid #555; 
            background-color: #1e1e1e;
            border-radius: 4px;
        }
        QLabel { color: #ffffff; }
    """)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    if not WHISPER_AVAILABLE and not VOSK_AVAILABLE:
        QMessageBox.critical(None, "Error", 
                           "No STT models available.\n"
                           "Please install: pip install openai-whisper OR pip install vosk")
        sys.exit(1)
    
    window = STTDemoMainWindow()
    window.show()
    
    sys.exit(app.exec_())


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ëª…ë ¹ì–´ íŒŒì‹±
    if len(sys.argv) < 2:
        command = "gui"  # ê¸°ë³¸ê°’
    else:
        command = sys.argv[1].lower()
    
    if command == "help":
        show_help()
    elif command == "check":
        print("ğŸ“‹ Checking packages...")
        if check_requirements():
            print("âœ… All required packages installed")
            check_optional_packages()
        else:
            print("âŒ Missing required packages")
    elif command == "install":
        print("ğŸ“¦ Installing packages...")
        install_packages()
    elif command == "gui" or command not in ["help", "check", "install"]:
        print("ğŸ¤ STT Demo Starting...")
        print("=" * 50)
        
        if not check_requirements():
            print("âŒ Missing required packages. Run: python stt_demo.py install")
            return
        
        available = check_optional_packages()
        if not (available.get('whisper') or available.get('vosk')):
            print("âš ï¸  Please install at least one STT model:")
            print("   pip install openai-whisper  # For Whisper")
            print("   pip install vosk           # For Vosk")
            return
        
        run_gui()
    else:
        print(f"âŒ Unknown command: {command}")
        show_help()


if __name__ == "__main__":
    main()